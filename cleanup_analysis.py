#!/usr/bin/env python3
"""
UK Financial Services Project Cleanup Analysis
–ê–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ—á–∏—Å—Ç–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
"""

import os
import json
from pathlib import Path
from datetime import datetime
import shutil

class ProjectAnalyzer:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.analysis_result = {
            "essential_files": [],
            "duplicate_files": [],
            "obsolete_files": [],
            "cleanup_recommendations": []
        }

    def analyze_project(self):
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞"""
        print("üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞ UK Financial Services...")

        # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–°–û–•–†–ê–ù–ò–¢–¨)
        essential_patterns = [
            # Backend core
            "backend/main.py",
            "backend/requirements.txt",
            "backend/app/",
            "backend/Dockerfile",
            "backend/.env*",

            # Frontend core
            "frontend/src/",
            "frontend/public/",
            "frontend/package.json",
            "frontend/vite.config.ts",
            "frontend/tsconfig.json",
            "frontend/tailwind.config.js",
            "frontend/Dockerfile",

            # Infrastructure
            "docker-compose*.yml",
            "nginx/",

            # Documentation
            "README.md",
            "project.json",
            "*_GUIDE.md",
            "*_DOCUMENTATION.md",
            "*_PLAN.md", # <-- –î–û–ë–ê–í–õ–ï–ù–û: –†–∞–∑—Ä–µ—à–∞–µ–º —Ñ–∞–π–ª—ã —Å –ø–ª–∞–Ω–∞–º–∏

            # Scripts (core only)
            "scripts/",

            # Tests
            "tests/"
        ]

        # –§–∞–π–ª—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        obsolete_patterns = [
            # –°—Ç–∞—Ä—ã–µ HTML –¥–µ–º–æ
            "*demo*.html",
            "*DEMO*.html",
            "*working*.html",
            "*fixed*.html",
            "*perfect*.html",
            "corrected_*.html",
            "system_status.html",
            "diagnostic_test.html",

            # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ Python —Å–∫—Ä–∏–ø—Ç—ã
            "quick_*.py",
            "simple_*.py",
            "working_*.py",
            "perfect_*.py",
            "launch_*.py",
            "fresh_*.py",
            "start_*.py",
            "force_*.py",
            "full_*.py",
            "run_*.py",
            "*–ó–ê–ü–£–°–ö*.py",
            "*–ò–°–ü–†–ê–í*.py",
            "*–≠–ö–°–¢–†–ï–ù*.py",

            # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ .bat —Ñ–∞–π–ª—ã (–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ)
            "*.bat",  # –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ

            # –°—Ç–∞—Ä—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            "demo.db",
            "working_demo.db",
            "*.db",  # –ö—Ä–æ–º–µ –æ—Å–Ω–æ–≤–Ω–æ–π

            # –ö—ç—à –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            "__pycache__/",
            "*.pyc",
            ".pytest_cache/",
            "node_modules/",

            # –°—Ç–∞—Ä—ã–µ –∞—Ä—Ö–∏–≤—ã (–µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ)
            "archive/old-*",

            # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            "venv_*/",
            ".venv/"
        ]

        self.scan_files(essential_patterns, obsolete_patterns)
        self.analyze_duplicates()
        self.generate_recommendations()

        return self.analysis_result

    def scan_files(self, essential_patterns, obsolete_patterns):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º"""

        for root, dirs, files in os.walk(self.project_root):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º node_modules –∏ –ø–æ–¥–æ–±–Ω—ã–µ
            dirs[:] = [d for d in dirs if d not in ['node_modules', '__pycache__', '.git', 'venv', '.venv']]

            for file in files:
                file_path = Path(root) / file
                rel_path = file_path.relative_to(self.project_root)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
                if self.match_patterns(str(rel_path), essential_patterns):
                    self.analysis_result["essential_files"].append(str(rel_path))

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ —Ñ–∞–π–ª—ã
                elif self.match_patterns(str(rel_path), obsolete_patterns):
                    self.analysis_result["obsolete_files"].append(str(rel_path))

    def match_patterns(self, file_path, patterns):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º"""
        import fnmatch

        for pattern in patterns:
            if fnmatch.fnmatch(file_path, pattern) or pattern in file_path:
                return True
        return False

    def analyze_duplicates(self):
        """–ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""

        # –ì—Ä—É–ø–ø—ã –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        duplicate_groups = {
            "launch_scripts": [
                "LAUNCH_UK_FINANCIAL_SERVICES.bat",
                "start.bat",
                "run.bat",
                "launch_fresh.bat",
                "clean_launch.bat",
                "force_update.bat"
            ],
            "demo_html": [
                "UK_FINANCIAL_SERVICES_DEMO.html",
                "perfect_working_demo.html",
                "working_demo.html",
                "working_demo_fixed.html",
                "fixed_active_modules.html"
            ],
            "backend_scripts": [
                "uk_financial_services_backend.py",
                "perfect_backend.py",
                "simple_backend.py"
            ]
        }

        for group_name, files in duplicate_groups.items():
            existing_files = []
            for file in files:
                if (self.project_root / file).exists():
                    existing_files.append(file)

            if len(existing_files) > 1:
                self.analysis_result["duplicate_files"].append({
                    "group": group_name,
                    "files": existing_files,
                    "recommend_keep": existing_files[0]  # –ü–µ—Ä–≤—ã–π –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
                })

    def generate_recommendations(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""

        recommendations = [
            {
                "category": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞",
                "action": "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É",
                "details": "backend/ + frontend/ + docker configs"
            },
            {
                "category": "–£–¥–∞–ª–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ HTML –¥–µ–º–æ",
                "action": "–£–¥–∞–ª–∏—Ç—å –≤—Å–µ *.html —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ",
                "details": "React frontend –∑–∞–º–µ–Ω—è–µ—Ç —Å—Ç–∞—Ä—ã–µ HTML –¥–µ–º–æ"
            },
            {
                "category": "–ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Å–∫—Ä–∏–ø—Ç—ã –∑–∞–ø—É—Å–∫–∞",
                "action": "–û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ docker-compose –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ .bat",
                "details": "–£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ launch/start —Å–∫—Ä–∏–ø—Ç—ã"
            },
            {
                "category": "–û—á–∏—Å—Ç–∏—Ç—å Python —Å–∫—Ä–∏–ø—Ç—ã",
                "action": "–û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ backend/main.py",
                "details": "–£–¥–∞–ª–∏—Ç—å legacy Python —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ"
            },
            {
                "category": "–£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö",
                "action": "–û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á—É—é –ë–î",
                "details": "–£–¥–∞–ª–∏—Ç—å demo.db, working_demo.db –∏ –ø—Ä–æ—á–∏–µ —Ç–µ—Å—Ç–æ–≤—ã–µ"
            }
        ]

        self.analysis_result["cleanup_recommendations"] = recommendations

    def save_analysis(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞"""

        report_file = self.project_root / "CLEANUP_ANALYSIS_REPORT.json"

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_result, f, indent=2, ensure_ascii=False)

        print(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
        return report_file

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""

    project_root = Path(__file__).parent
    analyzer = ProjectAnalyzer(project_root)

    print("üöÄ UK Financial Services - –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞")
    print("=" * 50)

    result = analyzer.analyze_project()
    report_file = analyzer.save_analysis()

    # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"‚úÖ –í–∞–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(result['essential_files'])}")
    print(f"üîÑ –ì—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(result['duplicate_files'])}")
    print(f"‚ùå –£—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(result['obsolete_files'])}")

    print(f"\nüìã –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ({len(result['cleanup_recommendations'])} –ø—É–Ω–∫—Ç–æ–≤):")
    for i, rec in enumerate(result['cleanup_recommendations'], 1):
        print(f"{i}. {rec['category']}: {rec['action']}")

    print(f"\nüìÑ –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç: {report_file}")

    return result

if __name__ == "__main__":
    main()
